---
layout: post
title: "Making the Most of Async in Node.js"
topics: [Concurrency, Development]
---

If you're trying to get a lot of unrelated tasks done in Node.js or similar languages, the
default behavior is often close enough to best case that most people don't bother doing more
than a little bit of tuning. But as the workload increases, and particularly if you are 
attempting to do any sort of offline (batch) processing in Node.js, the gap between simple
and fast can reach into orders of magnitude and can be worth digging a lot deeper.

This is the beginning of a series to go over both my existing knowledge and further
lessons learned while trying to get maximum value from leveraging the 
[p-limit](https://github.com/sindresorhus/p-limit) library for everything it is worth.

## Background

Before we get going, I feel it's important to discuss the distinction between offline and online 
processes.

### Offline vs Online Processes

"Online" is communication that expects an immediate answer, while "offline" has a much more
forgiving completion date. Consider, for instance, a fast food restaurant. The cashier 
taking your order is expected to enter it immediately, while the person washing dishes only 
needs to complete the task sooner rather than later. In fact if a bus of people show up at
the store, the person washing dishes may be asked to pause that work to help out with making
food. 

As a general rule, offline tasks should not interfere with the timeliness of online ones.

### Back Pressure

A lot of async code ends up getting used for talking to other services, which means a 
distributed system. Two of the more important tricks in distributed systems are back pressure
and work stealing. Work stealing is about poaching tasks from the queues of other processes or
threads in order to clear a work queue sooner. Without it, the very last task in a group can end
up being started after all other tasks have been finished, greatly increasing the latency 
between starting a batch of tasks and finishing them. So when a process runs out of work it may
try to remove tasks from the queue of another process in order to begin working on it sooner.

The other trick is back pressure. Back pressure is a way to force one step in a workflow to
slow down to not go faster than a subsequent step. This can keep partially completed work 
from stacking up, which can create overhead that reduces the number of tasks that get completed
per second, due to CPU or memory contention. Sometimes going slower allows you to go faster. 
